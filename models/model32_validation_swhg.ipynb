{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train-parking.csv', parse_dates=[[3,4]], infer_datetime_format=True)\n",
    "test=pd.read_csv('../data/test-no-label-parking.csv', parse_dates=[[3,4]], infer_datetime_format=True)\n",
    "# valid_dow = pd.read_csv('../data/valid_dow.csv', infer_datetime_format=True, index_col='index').set_index('index.1')\n",
    "# valid_hg = pd.read_csv('../data/valid_hg.csv', infer_datetime_format=True, index_col='index').set_index('index.1')\n",
    "valid_swhg = pd.read_csv('../data/valid_swhg.csv', infer_datetime_format=True, index_col='index').set_index('index.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Street</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Real.Spots</th>\n",
       "      <th>Street.Length</th>\n",
       "      <th>any_spot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-07 16:19:00</td>\n",
       "      <td>Mission Street</td>\n",
       "      <td>25th Street</td>\n",
       "      <td>26th Street</td>\n",
       "      <td>4</td>\n",
       "      <td>179.132970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-18 20:42:00</td>\n",
       "      <td>Polk Street</td>\n",
       "      <td>Ellis Street</td>\n",
       "      <td>Olive Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.740210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-18 20:39:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Geary Boulevard</td>\n",
       "      <td>Myrtle Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.517840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-18 20:38:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Bush Street</td>\n",
       "      <td>Fern Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.405315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-18 20:38:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Daniel Burnham Court</td>\n",
       "      <td>Post Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.191193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date_Time           Street                  From             To  \\\n",
       "0 2014-01-07 16:19:00   Mission Street           25th Street    26th Street   \n",
       "1 2014-01-18 20:42:00      Polk Street          Ellis Street   Olive Street   \n",
       "2 2014-01-18 20:39:00  Van Ness Avenue       Geary Boulevard  Myrtle Street   \n",
       "3 2014-01-18 20:38:00  Van Ness Avenue           Bush Street    Fern Street   \n",
       "4 2014-01-18 20:38:00  Van Ness Avenue  Daniel Burnham Court    Post Street   \n",
       "\n",
       "   Real.Spots  Street.Length  any_spot  \n",
       "0           4     179.132970         1  \n",
       "1           0      52.740210         0  \n",
       "2           0      52.517840         0  \n",
       "3           0      52.405315         0  \n",
       "4           0      52.191193         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the proper train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_dow = train[~train.index.isin(valid_dow.index)]\n",
    "# train_hg = train[~train.index.isin(valid_hg.index)]\n",
    "train_swhg = train[~train.index.isin(valid_swhg.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select validation set - round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get long and lat for train street\n",
    "st_latlng = pd.read_csv(\"../data/train_longlat.csv\", index_col = False,  dtype = {'lat':np.float64,'lng':np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_swhg = pd.merge(train_swhg,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "valid_swhg= pd.merge(valid_swhg,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sensor related data\n",
    "sensor = pd.read_csv('../data/aggregated_sensor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensor['TIME_OF_DAY'] = sensor['TIME_OF_DAY']/100\n",
    "sensor['TIME_OF_DAY'] = sensor['TIME_OF_DAY'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "spots = np.vstack(train_swhg[['lat','lng']].values)\n",
    "kmeans = KMeans().fit(spots)\n",
    "train_swhg['street_cluster'] = kmeans.predict(train_swhg[['lat', 'lng']])\n",
    "valid_swhg['street_cluster'] = kmeans.predict(valid_swhg[['lat', 'lng']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Time features\n",
    "train_swhg['Minute'] = train_swhg.Date_Time.dt.minute\n",
    "valid_swhg['Minute'] = pd.to_datetime(valid_swhg['Date_Time']).dt.minute\n",
    "train_swhg['Hour'] = train_swhg.Date_Time.dt.hour\n",
    "valid_swhg['Hour'] = pd.to_datetime(valid_swhg['Date_Time']).dt.hour\n",
    "train_swhg['Dow'] = train_swhg.Date_Time.dt.weekday\n",
    "valid_swhg['Dow'] = pd.to_datetime(valid_swhg['Date_Time']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the time (Hour, Minute) to a numerical value XXXX\n",
    "train_swhg['Time'] = train_swhg[\"Hour\"]*100 + train_swhg['Minute']\n",
    "valid_swhg['Time'] = valid_swhg[\"Hour\"]*100 + valid_swhg['Minute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def day_type(x):\n",
    "    if x == 6 or x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "train_swhg['isweekend'] = train_swhg['Dow'].apply(day_type)\n",
    "valid_swhg['isweekend'] = valid_swhg['Dow'].apply(day_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Single mean encoding\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def multi_reg_mean_encoding(train, cols, splits =5):\n",
    "    kf = KFold(n_splits = splits)\n",
    "    global_mean = train.any_spot.mean()\n",
    "    \n",
    "    for col in cols:\n",
    "        means = train.groupby(col).any_spot.mean()\n",
    "        train[col+'_mean_enc'] = train[col].map(means)        \n",
    "        for tr_ind,val_ind in kf.split(train):\n",
    "            tr,val = train.iloc[tr_ind],train.iloc[val_ind]\n",
    "            foldmeans = tr.groupby(col).any_spot.mean()\n",
    "            train.loc[val_ind,col+\"_mean_enc\"] = train.loc[val_ind,col].map(foldmeans)    \n",
    "        train[col+\"_mean_enc\"].fillna(global_mean,inplace=True)   \n",
    "        \n",
    "#mean encoding for validation and test data\n",
    "def multi_test_mean_encoding(test, train, cols):\n",
    "    for col in cols:\n",
    "        global_mean = train.any_spot.mean()\n",
    "        means = train.groupby(col).any_spot.mean()\n",
    "        test[col+\"_mean_enc\"] = test[col].map(means)\n",
    "        test[col+\"_mean_enc\"].fillna(global_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a column for From_To pair\n",
    "train_swhg['From_To'] = train_swhg['From'] + '_' + train_swhg['To']\n",
    "valid_swhg['From_To'] = valid_swhg['From'] + '_' + valid_swhg['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Dow','isweekend','From_To','Street','Hour', 'street_cluster' ]\n",
    "multi_reg_mean_encoding(train_swhg, cols, splits =5)\n",
    "multi_test_mean_encoding(valid_swhg, train_swhg, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Double variable mean encoding\n",
    "colpairs = [('street_cluster','Dow'),('Dow','Hour'), ('street_cluster','Hour'),\n",
    "            ('street_cluster','isweekend'),('From_To','Dow'),('From_To','Hour')]\n",
    "pairlist = []\n",
    "for pair in colpairs:\n",
    "    colname = pair[0] + '_' + pair[1]\n",
    "    pairlist.append(colname)\n",
    "    train_swhg[colname] = list(zip(train_swhg[pair[0]], train_swhg[pair[1]]))\n",
    "    valid_swhg[colname] = list(zip(valid_swhg[pair[0]], valid_swhg[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_reg_mean_encoding(train_swhg, pairlist, splits =5)\n",
    "multi_test_mean_encoding(valid_swhg, train_swhg, pairlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop Data_Time, Real.Spots, street_cluster_Dow, Dow_Hour, street_cluster_Hour, street_cluster_isweekend, From_To_Dow, From_To_Hour\n",
    "train_swhg = train_swhg.drop(['Date_Time','Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis =1)\n",
    "valid_swhg = valid_swhg.drop(['Date_Time', 'Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_swhg['Street'] = train_swhg.Street.str.lower()\n",
    "train_swhg['From'] = train_swhg.From.str.lower()\n",
    "train_swhg['To'] = train_swhg.To.str.lower()\n",
    "valid_swhg['Street'] = valid_swhg.Street.str.lower()\n",
    "valid_swhg['From'] = valid_swhg.From.str.lower()\n",
    "valid_swhg['To'] = valid_swhg.To.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join sensor data:\n",
    "train_swhg = pd.merge(train_swhg,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "valid_swhg = pd.merge(valid_swhg,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "\n",
    "train_swhg = train_swhg.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)\n",
    "valid_swhg = valid_swhg.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert categorical variables to code\n",
    "def process_dfs(train_df, test_df, cols):\n",
    "    # transfer categorical \n",
    "    for name in cols:\n",
    "        train_df[name]=train_df[name].astype('category').cat.as_ordered()\n",
    "        test_df[name] = pd.Categorical(test_df[name], categories=train_df[name].cat.categories, ordered=True)\n",
    "    return train_df, test_df\n",
    "  \n",
    "def cat2code(train_df, test_df, cols):\n",
    "    # transfer categorical \n",
    "    for name in cols:\n",
    "        train_df[name]= train_df[name].cat.codes\n",
    "        test_df[name] = test_df[name].cat.codes\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catcols = ['Street','From','To', 'From_To']\n",
    "train_swhg,valid_swhg = process_dfs(train_swhg.copy(),valid_swhg.copy(),catcols)\n",
    "train_swhg,valid_swhg = cat2code(train_swhg,valid_swhg,catcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y\n",
    "def split_response(df, response):\n",
    "    y = df[response].values\n",
    "    df.drop([response],axis=1,inplace=True)\n",
    "    return df,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_swhg,y_train_swhg = split_response(train_swhg.copy(),'any_spot')\n",
    "X_valid_swhg,y_valid_swhg = split_response(valid_swhg.copy(),'any_spot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f05_score_soft(labels, preds):\n",
    "    tp = np.sum((labels==(preds>0.5)) & (labels==1))\n",
    "    tn = np.sum((labels==(preds<0.5)) & (labels==0))\n",
    "    fp = np.sum((preds>0.5))-tp\n",
    "    fn = np.sum(preds<0.5)-tn\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "    score = 1.25*p*r/(0.25*p+r)\n",
    "    return score\n",
    "\n",
    "def f05_score_hard(labels, preds):\n",
    "    tp = np.sum((labels==preds) & (labels==1))\n",
    "    tn = np.sum((labels==preds) & (labels==0))\n",
    "    fp = np.sum(preds==1)-tp\n",
    "    fn = np.sum(preds==0)-tn\n",
    "#    print(tp, tn, fp, fn)\n",
    "    p = tp*1.0/(tp+fp)\n",
    "    r = tp*1.0/(tp+fn)\n",
    "    score = 1.25*p*r/(0.25*p+r)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manual gridsearch using validation set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import itertools\n",
    "\n",
    "n_estimators = [20, 40, 60, 80]\n",
    "max_depth = [3,5,10,15,20,25,30]\n",
    "max_features = [0.2,0.4,0.5,0.6,0.8,0.9,1]\n",
    "weight = [0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "para_lists = [n_estimators, max_depth, max_features, weight]\n",
    "combo = list(itertools.product(*para_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = []\n",
    "f05 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for p in combo:\n",
    "    np.random.seed(42)\n",
    "    m = RandomForestClassifier(n_estimators = p[0], max_depth =p[1], max_features=p[2],class_weight={0:1,1:p[3]}, min_samples_split = 2, n_jobs=-1)\n",
    "    m.fit(X_train_swhg,y_train_swhg)\n",
    "    pred = m.predict(X_valid_swhg)\n",
    "    prec = precision_score(y_valid_swhg, pred)\n",
    "    rec = recall_score(y_valid_swhg, pred)\n",
    "    f = f05_score_hard(y_valid_swhg, pred)\n",
    "    parameters.append(p)\n",
    "    f05.append(f)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "\n",
    "table3 = pd.DataFrame({'Parameters': parameters, 'f0.5': f05, 'precision':precision, 'recall':recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table3.sort_values('f0.5', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>f0.5</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>(80, 25, 1, 0.9)</td>\n",
       "      <td>0.578035</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>(80, 30, 1, 0.9)</td>\n",
       "      <td>0.562130</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>(20, 10, 1, 1.1)</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>(80, 20, 1, 0.9)</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>(60, 10, 0.2, 1.2)</td>\n",
       "      <td>0.547264</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.385965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Parameters      f0.5  precision    recall\n",
       "1694    (80, 25, 1, 0.9)  0.578035   0.689655  0.350877\n",
       "1757    (80, 30, 1, 0.9)  0.562130   0.678571  0.333333\n",
       "184     (20, 10, 1, 1.1)  0.560976   0.621622  0.403509\n",
       "1631    (80, 20, 1, 0.9)  0.552486   0.645161  0.350877\n",
       "1013  (60, 10, 0.2, 1.2)  0.547264   0.611111  0.385965"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the best hyperparameters (80, 25, 1, 0.9) to get feature importance:\n",
    "np.random.seed(42)\n",
    "m2 = RandomForestClassifier(n_estimators = 80, max_depth =25, max_features=1, class_weight={0:1,1:0.9}, min_samples_split = 2, n_jobs=-1)\n",
    "m2.fit(X_train_swhg,y_train_swhg)\n",
    "\n",
    "feat_imp_swhg = pd.DataFrame({\n",
    "    'features': X_train_swhg.columns,\n",
    "    'imp' :m2.feature_importances_\n",
    "})\n",
    "feat_imp_swhg.sort_values(by='imp', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36454545454545456"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.any_spot.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Street.Length</td>\n",
       "      <td>0.046423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From_To_mean_enc</td>\n",
       "      <td>0.045269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.039527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Minute</td>\n",
       "      <td>0.038951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From_To</td>\n",
       "      <td>0.038211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To</td>\n",
       "      <td>0.035782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lat</td>\n",
       "      <td>0.035762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lng</td>\n",
       "      <td>0.035020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From</td>\n",
       "      <td>0.030952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>From_To_Dow_mean_enc</td>\n",
       "      <td>0.027485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NONOP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.026619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Street_mean_enc</td>\n",
       "      <td>0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TOTAL_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.024050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hour_mean_enc</td>\n",
       "      <td>0.023513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>street_cluster_Hour_mean_enc</td>\n",
       "      <td>0.023345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TOTAL_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.023298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>street_cluster_mean_enc</td>\n",
       "      <td>0.022806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>street_cluster_isweekend_mean_enc</td>\n",
       "      <td>0.022605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dow_Hour_mean_enc</td>\n",
       "      <td>0.022433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NONOP_VACANT_TIME_pct</td>\n",
       "      <td>0.021075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TOTAL_VACANT_TIME_pct</td>\n",
       "      <td>0.020638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hour</td>\n",
       "      <td>0.019399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>isweekend_mean_enc</td>\n",
       "      <td>0.019348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>street_cluster_Dow_mean_enc</td>\n",
       "      <td>0.019319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NONOP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dow_mean_enc</td>\n",
       "      <td>0.019006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From_To_Hour_mean_enc</td>\n",
       "      <td>0.018811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>OP_VACANT_TIME_pct</td>\n",
       "      <td>0.018045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TOTAL_TIME_spots</td>\n",
       "      <td>0.017668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>OP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.017530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>OP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.017306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Street</td>\n",
       "      <td>0.016349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GMP_VACANT_TIME_pct</td>\n",
       "      <td>0.016127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GMP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.015896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NONOP_TIME_spots</td>\n",
       "      <td>0.015424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dow</td>\n",
       "      <td>0.015382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>street_cluster</td>\n",
       "      <td>0.015090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GMP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.015089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>COMM_VACANT_TIME_pct</td>\n",
       "      <td>0.014596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GMP_TIME_spots</td>\n",
       "      <td>0.014169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>COMM_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.012946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>OP_TIME_spots</td>\n",
       "      <td>0.011455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>COMM_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.010160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>COMM_TIME_spots</td>\n",
       "      <td>0.008902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>isweekend</td>\n",
       "      <td>0.004969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             features       imp\n",
       "3                       Street.Length  0.046423\n",
       "15                   From_To_mean_enc  0.045269\n",
       "10                               Time  0.039527\n",
       "7                              Minute  0.038951\n",
       "12                            From_To  0.038211\n",
       "2                                  To  0.035782\n",
       "4                                 lat  0.035762\n",
       "5                                 lng  0.035020\n",
       "1                                From  0.030952\n",
       "23               From_To_Dow_mean_enc  0.027485\n",
       "31            NONOP_OCCUPIED_TIME_pct  0.026619\n",
       "16                    Street_mean_enc  0.024093\n",
       "25            TOTAL_OCCUPIED_TIME_pct  0.024050\n",
       "17                      Hour_mean_enc  0.023513\n",
       "21       street_cluster_Hour_mean_enc  0.023345\n",
       "27             TOTAL_UNKNOWN_TIME_pct  0.023298\n",
       "18            street_cluster_mean_enc  0.022806\n",
       "22  street_cluster_isweekend_mean_enc  0.022605\n",
       "20                  Dow_Hour_mean_enc  0.022433\n",
       "32              NONOP_VACANT_TIME_pct  0.021075\n",
       "26              TOTAL_VACANT_TIME_pct  0.020638\n",
       "8                                Hour  0.019399\n",
       "14                 isweekend_mean_enc  0.019348\n",
       "19        street_cluster_Dow_mean_enc  0.019319\n",
       "33             NONOP_UNKNOWN_TIME_pct  0.019157\n",
       "13                       Dow_mean_enc  0.019006\n",
       "24              From_To_Hour_mean_enc  0.018811\n",
       "29                 OP_VACANT_TIME_pct  0.018045\n",
       "40                   TOTAL_TIME_spots  0.017668\n",
       "28               OP_OCCUPIED_TIME_pct  0.017530\n",
       "30                OP_UNKNOWN_TIME_pct  0.017306\n",
       "0                              Street  0.016349\n",
       "35                GMP_VACANT_TIME_pct  0.016127\n",
       "36               GMP_UNKNOWN_TIME_pct  0.015896\n",
       "42                   NONOP_TIME_spots  0.015424\n",
       "9                                 Dow  0.015382\n",
       "6                      street_cluster  0.015090\n",
       "34              GMP_OCCUPIED_TIME_pct  0.015089\n",
       "38               COMM_VACANT_TIME_pct  0.014596\n",
       "43                     GMP_TIME_spots  0.014169\n",
       "37             COMM_OCCUPIED_TIME_pct  0.012946\n",
       "41                      OP_TIME_spots  0.011455\n",
       "39              COMM_UNKNOWN_TIME_pct  0.010160\n",
       "44                    COMM_TIME_spots  0.008902\n",
       "11                          isweekend  0.004969"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_swhg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_drop_swhg = feat_imp_swhg[feat_imp_swhg['imp'] <= 0.015].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOW-retrain entire model - remember to drop insignificant columns in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "test= pd.merge(test,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "\n",
    "spots = np.vstack(train[['lat','lng']].values)\n",
    "kmeans = KMeans().fit(spots)\n",
    "train['street_cluster'] = kmeans.predict(train[['lat', 'lng']])\n",
    "test['street_cluster'] = kmeans.predict(test[['lat', 'lng']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Minute'] = train.Date_Time.dt.minute\n",
    "test['Minute'] = pd.to_datetime(test['Date_Time']).dt.minute\n",
    "train['Hour'] = train.Date_Time.dt.hour\n",
    "test['Hour'] = pd.to_datetime(test['Date_Time']).dt.hour\n",
    "train['Dow'] = train.Date_Time.dt.weekday\n",
    "test['Dow'] = pd.to_datetime(test['Date_Time']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Time'] = train[\"Hour\"]*100 + train['Minute']\n",
    "test['Time'] = test[\"Hour\"]*100 + test['Minute']\n",
    "train['isweekend'] = train['Dow'].apply(day_type)\n",
    "test['isweekend'] = test['Dow'].apply(day_type)\n",
    "train['From_To'] = train['From'] + '_' + train['To']\n",
    "test['From_To'] = test['From'] + '_' + test['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Dow','isweekend','From_To','Street','Hour', 'street_cluster' ]\n",
    "multi_reg_mean_encoding(train, cols, splits =5)\n",
    "multi_test_mean_encoding(test, train, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colpairs = [('street_cluster','Dow'),('Dow','Hour'), ('street_cluster','Hour'),\n",
    "            ('street_cluster','isweekend'),('From_To','Dow'),('From_To','Hour')]\n",
    "pairlist = []\n",
    "for pair in colpairs:\n",
    "    colname = pair[0] + '_' + pair[1]\n",
    "    pairlist.append(colname)\n",
    "    train[colname] = list(zip(train[pair[0]], train[pair[1]]))\n",
    "    test[colname] = list(zip(test[pair[0]], test[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_reg_mean_encoding(train, pairlist, splits =5)\n",
    "multi_test_mean_encoding(test, train, pairlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Date_Time','Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis =1)\n",
    "test = test.drop(['Date_Time', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Street'] = train.Street.str.lower()\n",
    "train['From'] = train.From.str.lower()\n",
    "train['To'] = train.To.str.lower()\n",
    "test['Street'] = test.Street.str.lower()\n",
    "test['From'] = test.From.str.lower()\n",
    "test['To'] = test.To.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "test = pd.merge(test,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "\n",
    "train = train.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)\n",
    "test = test.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catcols = ['Street','From','To', 'From_To']\n",
    "train,test = process_dfs(train.copy(),test.copy(),catcols)\n",
    "train,test = cat2code(train,test,catcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train = split_response(train.copy(),'any_spot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop unimportant features\n",
    "X_train.drop(to_drop_swhg, axis = 1, inplace=True)\n",
    "test.drop(to_drop_swhg, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit rf\n",
    "np.random.seed(42)\n",
    "m_swhg = RandomForestClassifier(n_estimators = 80, max_depth =25, max_features=1, class_weight={0:1,1:0.9}, min_samples_split = 2, n_jobs=-1)\n",
    "m_swhg.fit(X_train,y_train)\n",
    "pred_swhg = m_swhg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"id\": np.arange(1,len(test)+1),\"any_spot\":pred_swhg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result[['id','any_spot']].to_csv(\"../submissions/32_swhg_test.csv\", index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Street-dow-hour_group:\n",
    "\n",
    "Result from leaderboard: 0.56851\n",
    "\n",
    "on validation set: 0.578035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
