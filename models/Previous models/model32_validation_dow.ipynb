{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train-parking.csv', parse_dates=[[3,4]], infer_datetime_format=True)\n",
    "test=pd.read_csv('../data/test-no-label-parking.csv', parse_dates=[[3,4]], infer_datetime_format=True)\n",
    "valid_dow = pd.read_csv('../data/valid_dow.csv', infer_datetime_format=True, index_col='index').set_index('index.1')\n",
    "valid_hg = pd.read_csv('../data/valid_hg.csv', infer_datetime_format=True, index_col='index').set_index('index.1')\n",
    "valid_swhg = pd.read_csv('../data/valid_swhg.csv', infer_datetime_format=True, index_col='index').set_index('index.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Street</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Real.Spots</th>\n",
       "      <th>Street.Length</th>\n",
       "      <th>any_spot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-07 16:19:00</td>\n",
       "      <td>Mission Street</td>\n",
       "      <td>25th Street</td>\n",
       "      <td>26th Street</td>\n",
       "      <td>4</td>\n",
       "      <td>179.132970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-18 20:42:00</td>\n",
       "      <td>Polk Street</td>\n",
       "      <td>Ellis Street</td>\n",
       "      <td>Olive Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.740210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-18 20:39:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Geary Boulevard</td>\n",
       "      <td>Myrtle Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.517840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-18 20:38:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Bush Street</td>\n",
       "      <td>Fern Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.405315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-18 20:38:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Daniel Burnham Court</td>\n",
       "      <td>Post Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.191193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date_Time           Street                  From             To  \\\n",
       "0 2014-01-07 16:19:00   Mission Street           25th Street    26th Street   \n",
       "1 2014-01-18 20:42:00      Polk Street          Ellis Street   Olive Street   \n",
       "2 2014-01-18 20:39:00  Van Ness Avenue       Geary Boulevard  Myrtle Street   \n",
       "3 2014-01-18 20:38:00  Van Ness Avenue           Bush Street    Fern Street   \n",
       "4 2014-01-18 20:38:00  Van Ness Avenue  Daniel Burnham Court    Post Street   \n",
       "\n",
       "   Real.Spots  Street.Length  any_spot  \n",
       "0           4     179.132970         1  \n",
       "1           0      52.740210         0  \n",
       "2           0      52.517840         0  \n",
       "3           0      52.405315         0  \n",
       "4           0      52.191193         0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the proper train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dow = train[~train.index.isin(valid_dow.index)]\n",
    "train_hg = train[~train.index.isin(valid_hg.index)]\n",
    "train_swhg = train[~train.index.isin(valid_swhg.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select validation set - round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get long and lat for train street\n",
    "st_latlng = pd.read_csv(\"../data/train_longlat.csv\", index_col = False,  dtype = {'lat':np.float64,'lng':np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dow = pd.merge(train_dow,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "valid_dow= pd.merge(valid_dow,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sensor related data\n",
    "sensor = pd.read_csv('../data/aggregated_sensor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensor['TIME_OF_DAY'] = sensor['TIME_OF_DAY']/100\n",
    "sensor['TIME_OF_DAY'] = sensor['TIME_OF_DAY'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "spots = np.vstack(train_dow[['lat','lng']].values)\n",
    "kmeans = KMeans().fit(spots)\n",
    "train_dow['street_cluster'] = kmeans.predict(train_dow[['lat', 'lng']])\n",
    "valid_dow['street_cluster'] = kmeans.predict(valid_dow[['lat', 'lng']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time features\n",
    "train_dow['Minute'] = train_dow.Date_Time.dt.minute\n",
    "valid_dow['Minute'] = pd.to_datetime(valid_dow['Date_Time']).dt.minute\n",
    "train_dow['Hour'] = train_dow.Date_Time.dt.hour\n",
    "valid_dow['Hour'] = pd.to_datetime(valid_dow['Date_Time']).dt.hour\n",
    "train_dow['Dow'] = train_dow.Date_Time.dt.weekday\n",
    "valid_dow['Dow'] = pd.to_datetime(valid_dow['Date_Time']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the time (Hour, Minute) to a numerical value XXXX\n",
    "train_dow['Time'] = train_dow[\"Hour\"]*100 + train_dow['Minute']\n",
    "valid_dow['Time'] = valid_dow[\"Hour\"]*100 + valid_dow['Minute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def day_type(x):\n",
    "    if x == 6 or x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "train_dow['isweekend'] = train_dow['Dow'].apply(day_type)\n",
    "valid_dow['isweekend'] = valid_dow['Dow'].apply(day_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Single mean encoding\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def multi_reg_mean_encoding(train, cols, splits =5):\n",
    "    kf = KFold(n_splits = splits)\n",
    "    global_mean = train.any_spot.mean()\n",
    "    \n",
    "    for col in cols:\n",
    "        means = train.groupby(col).any_spot.mean()\n",
    "        train[col+'_mean_enc'] = train[col].map(means)        \n",
    "        for tr_ind,val_ind in kf.split(train):\n",
    "            tr,val = train.iloc[tr_ind],train.iloc[val_ind]\n",
    "            foldmeans = tr.groupby(col).any_spot.mean()\n",
    "            train.loc[val_ind,col+\"_mean_enc\"] = train.loc[val_ind,col].map(foldmeans)    \n",
    "        train[col+\"_mean_enc\"].fillna(global_mean,inplace=True)   \n",
    "        \n",
    "#mean encoding for validation and test data\n",
    "def multi_test_mean_encoding(test, train, cols):\n",
    "    for col in cols:\n",
    "        global_mean = train.any_spot.mean()\n",
    "        means = train.groupby(col).any_spot.mean()\n",
    "        test[col+\"_mean_enc\"] = test[col].map(means)\n",
    "        test[col+\"_mean_enc\"].fillna(global_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a column for From_To pair\n",
    "train_dow['From_To'] = train_dow['From'] + '_' + train_dow['To']\n",
    "valid_dow['From_To'] = valid_dow['From'] + '_' + valid_dow['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Dow','isweekend','From_To','Street','Hour', 'street_cluster' ]\n",
    "multi_reg_mean_encoding(train_dow, cols, splits =5)\n",
    "multi_test_mean_encoding(valid_dow, train_dow, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Double variable mean encoding\n",
    "colpairs = [('street_cluster','Dow'),('Dow','Hour'), ('street_cluster','Hour'),\n",
    "            ('street_cluster','isweekend'),('From_To','Dow'),('From_To','Hour')]\n",
    "pairlist = []\n",
    "for pair in colpairs:\n",
    "    colname = pair[0] + '_' + pair[1]\n",
    "    pairlist.append(colname)\n",
    "    train_dow[colname] = list(zip(train_dow[pair[0]], train_dow[pair[1]]))\n",
    "    valid_dow[colname] = list(zip(valid_dow[pair[0]], valid_dow[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_reg_mean_encoding(train_dow, pairlist, splits =5)\n",
    "multi_test_mean_encoding(valid_dow, train_dow, pairlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop Data_Time, Real.Spots, street_cluster_Dow, Dow_Hour, street_cluster_Hour, street_cluster_isweekend, From_To_Dow, From_To_Hour\n",
    "train_dow = train_dow.drop(['Date_Time','Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis =1)\n",
    "valid_dow = valid_dow.drop(['Date_Time', 'Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dow['Street'] = train_dow.Street.str.lower()\n",
    "train_dow['From'] = train_dow.From.str.lower()\n",
    "train_dow['To'] = train_dow.To.str.lower()\n",
    "valid_dow['Street'] = valid_dow.Street.str.lower()\n",
    "valid_dow['From'] = valid_dow.From.str.lower()\n",
    "valid_dow['To'] = valid_dow.To.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join sensor data:\n",
    "train_dow = pd.merge(train_dow,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "valid_dow = pd.merge(valid_dow,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "\n",
    "train_dow = train_dow.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)\n",
    "valid_dow = valid_dow.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert categorical variables to code\n",
    "def process_dfs(train_df, test_df, cols):\n",
    "    # transfer categorical \n",
    "    for name in cols:\n",
    "        train_df[name]=train_df[name].astype('category').cat.as_ordered()\n",
    "        test_df[name] = pd.Categorical(test_df[name], categories=train_df[name].cat.categories, ordered=True)\n",
    "    return train_df, test_df\n",
    "  \n",
    "def cat2code(train_df, test_df, cols):\n",
    "    # transfer categorical \n",
    "    for name in cols:\n",
    "        train_df[name]= train_df[name].cat.codes\n",
    "        test_df[name] = test_df[name].cat.codes\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catcols = ['Street','From','To', 'From_To']\n",
    "train_dow,valid_dow = process_dfs(train_dow.copy(),valid_dow.copy(),catcols)\n",
    "train_dow,valid_dow = cat2code(train_dow,valid_dow,catcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y\n",
    "def split_response(df, response):\n",
    "    y = df[response].values\n",
    "    df.drop([response],axis=1,inplace=True)\n",
    "    return df,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_dow,y_train_dow = split_response(train_dow.copy(),'any_spot')\n",
    "X_valid_dow,y_valid_dow = split_response(valid_dow.copy(),'any_spot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f05_score_soft(labels, preds):\n",
    "    tp = np.sum((labels==(preds>0.5)) & (labels==1))\n",
    "    tn = np.sum((labels==(preds<0.5)) & (labels==0))\n",
    "    fp = np.sum((preds>0.5))-tp\n",
    "    fn = np.sum(preds<0.5)-tn\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "    score = 1.25*p*r/(0.25*p+r)\n",
    "    return score\n",
    "\n",
    "def f05_score_hard(labels, preds):\n",
    "    tp = np.sum((labels==preds) & (labels==1))\n",
    "    tn = np.sum((labels==preds) & (labels==0))\n",
    "    fp = np.sum(preds==1)-tp\n",
    "    fn = np.sum(preds==0)-tn\n",
    "#    print(tp, tn, fp, fn)\n",
    "    p = tp*1.0/(tp+fp)\n",
    "    r = tp*1.0/(tp+fn)\n",
    "    score = 1.25*p*r/(0.25*p+r)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manual gridsearch using validation set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import itertools\n",
    "\n",
    "n_estimators = [20, 40, 60, 80]\n",
    "max_depth = [3,5,10,15,20,25,30]\n",
    "max_features = [0.2,0.4,0.5,0.6,0.8,0.9,1]\n",
    "weight = [0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "para_lists = [n_estimators, max_depth, max_features, weight]\n",
    "combo = list(itertools.product(*para_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = []\n",
    "f05 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for p in combo:\n",
    "    np.random.seed(42)\n",
    "    m = RandomForestClassifier(n_estimators = p[0], max_depth =p[1], max_features=p[2],class_weight={0:1,1:p[3]}, min_samples_split = 2, n_jobs=-1)\n",
    "    m.fit(X_train_dow,y_train_dow)\n",
    "    pred = m.predict(X_valid_dow)\n",
    "    prec = precision_score(y_valid_dow, pred)\n",
    "    rec = recall_score(y_valid_dow, pred)\n",
    "    f = f05_score_hard(y_valid_dow, pred)\n",
    "    parameters.append(p)\n",
    "    f05.append(f)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "\n",
    "table1 = pd.DataFrame({'Parameters': parameters, 'f0.5': f05, 'precision':precision, 'recall':recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.sort_values('f0.5', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>f0.5</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>(40, 5, 0.4, 0.8)</td>\n",
       "      <td>0.616883</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(20, 3, 0.5, 0.8)</td>\n",
       "      <td>0.615672</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.434211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>(40, 5, 0.6, 0.7)</td>\n",
       "      <td>0.607639</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.460526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>(20, 5, 0.4, 1)</td>\n",
       "      <td>0.603933</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>(60, 3, 1, 1.4)</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.486842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Parameters      f0.5  precision    recall\n",
       "514  (40, 5, 0.4, 0.8)  0.616883   0.655172  0.500000\n",
       "19   (20, 3, 0.5, 0.8)  0.615672   0.687500  0.434211\n",
       "531  (40, 5, 0.6, 0.7)  0.607639   0.660377  0.460526\n",
       "75     (20, 5, 0.4, 1)  0.603933   0.614286  0.565789\n",
       "943    (60, 3, 1, 1.4)  0.600649   0.637931  0.486842"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the best hyperparameters (40, 5, 0.4, 0.8) to get feature importance:\n",
    "np.random.seed(42)\n",
    "m2 = RandomForestClassifier(n_estimators = 40, max_depth =5, max_features=0.4, class_weight={0:1,1:0.8}, min_samples_split = 2, n_jobs=-1)\n",
    "m2.fit(X_train_dow,y_train_dow)\n",
    "\n",
    "feat_imp_dow = pd.DataFrame({\n",
    "    'features': X_train_dow.columns,\n",
    "    'imp' :m2.feature_importances_\n",
    "})\n",
    "feat_imp_dow.sort_values(by='imp', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From_To_mean_enc</td>\n",
       "      <td>0.190730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Street.Length</td>\n",
       "      <td>0.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dow_Hour_mean_enc</td>\n",
       "      <td>0.069543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GMP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.038704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.037968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lng</td>\n",
       "      <td>0.035539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hour_mean_enc</td>\n",
       "      <td>0.031345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From_To</td>\n",
       "      <td>0.027748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lat</td>\n",
       "      <td>0.027581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To</td>\n",
       "      <td>0.025569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GMP_VACANT_TIME_pct</td>\n",
       "      <td>0.025101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NONOP_VACANT_TIME_pct</td>\n",
       "      <td>0.024449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>OP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.023443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TOTAL_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.022167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TOTAL_VACANT_TIME_pct</td>\n",
       "      <td>0.021712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Minute</td>\n",
       "      <td>0.019949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Street_mean_enc</td>\n",
       "      <td>0.018583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TOTAL_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.016576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>street_cluster_isweekend_mean_enc</td>\n",
       "      <td>0.016024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>From_To_Dow_mean_enc</td>\n",
       "      <td>0.015279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>COMM_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.014331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NONOP_TIME_spots</td>\n",
       "      <td>0.014234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>street_cluster_mean_enc</td>\n",
       "      <td>0.014119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NONOP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.013954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dow_mean_enc</td>\n",
       "      <td>0.013173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>street_cluster_Hour_mean_enc</td>\n",
       "      <td>0.012747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From</td>\n",
       "      <td>0.012546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NONOP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.011424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>street_cluster_Dow_mean_enc</td>\n",
       "      <td>0.011269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>COMM_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.011101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>COMM_VACANT_TIME_pct</td>\n",
       "      <td>0.010911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GMP_TIME_spots</td>\n",
       "      <td>0.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>OP_VACANT_TIME_pct</td>\n",
       "      <td>0.009674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Street</td>\n",
       "      <td>0.009515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>OP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.009378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TOTAL_TIME_spots</td>\n",
       "      <td>0.008841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>street_cluster</td>\n",
       "      <td>0.007737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dow</td>\n",
       "      <td>0.006816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>OP_TIME_spots</td>\n",
       "      <td>0.006481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GMP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.005903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>isweekend_mean_enc</td>\n",
       "      <td>0.005553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From_To_Hour_mean_enc</td>\n",
       "      <td>0.004570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hour</td>\n",
       "      <td>0.002850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>COMM_TIME_spots</td>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>isweekend</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             features       imp\n",
       "15                   From_To_mean_enc  0.190730\n",
       "3                       Street.Length  0.082700\n",
       "20                  Dow_Hour_mean_enc  0.069543\n",
       "36               GMP_UNKNOWN_TIME_pct  0.038704\n",
       "10                               Time  0.037968\n",
       "5                                 lng  0.035539\n",
       "17                      Hour_mean_enc  0.031345\n",
       "12                            From_To  0.027748\n",
       "4                                 lat  0.027581\n",
       "2                                  To  0.025569\n",
       "35                GMP_VACANT_TIME_pct  0.025101\n",
       "32              NONOP_VACANT_TIME_pct  0.024449\n",
       "30                OP_UNKNOWN_TIME_pct  0.023443\n",
       "27             TOTAL_UNKNOWN_TIME_pct  0.022167\n",
       "26              TOTAL_VACANT_TIME_pct  0.021712\n",
       "7                              Minute  0.019949\n",
       "16                    Street_mean_enc  0.018583\n",
       "25            TOTAL_OCCUPIED_TIME_pct  0.016576\n",
       "22  street_cluster_isweekend_mean_enc  0.016024\n",
       "23               From_To_Dow_mean_enc  0.015279\n",
       "37             COMM_OCCUPIED_TIME_pct  0.014331\n",
       "42                   NONOP_TIME_spots  0.014234\n",
       "18            street_cluster_mean_enc  0.014119\n",
       "33             NONOP_UNKNOWN_TIME_pct  0.013954\n",
       "13                       Dow_mean_enc  0.013173\n",
       "21       street_cluster_Hour_mean_enc  0.012747\n",
       "1                                From  0.012546\n",
       "31            NONOP_OCCUPIED_TIME_pct  0.011424\n",
       "19        street_cluster_Dow_mean_enc  0.011269\n",
       "39              COMM_UNKNOWN_TIME_pct  0.011101\n",
       "38               COMM_VACANT_TIME_pct  0.010911\n",
       "43                     GMP_TIME_spots  0.010633\n",
       "29                 OP_VACANT_TIME_pct  0.009674\n",
       "0                              Street  0.009515\n",
       "28               OP_OCCUPIED_TIME_pct  0.009378\n",
       "40                   TOTAL_TIME_spots  0.008841\n",
       "6                      street_cluster  0.007737\n",
       "9                                 Dow  0.006816\n",
       "41                      OP_TIME_spots  0.006481\n",
       "34              GMP_OCCUPIED_TIME_pct  0.005903\n",
       "14                 isweekend_mean_enc  0.005553\n",
       "24              From_To_Hour_mean_enc  0.004570\n",
       "8                                Hour  0.002850\n",
       "44                    COMM_TIME_spots  0.001530\n",
       "11                          isweekend  0.000000"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_dow = feat_imp_dow[feat_imp_dow['imp'] <= 0.01].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOW-retrain entire model - remember to drop insignificant columns in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "test= pd.merge(test,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "\n",
    "spots = np.vstack(train[['lat','lng']].values)\n",
    "kmeans = KMeans().fit(spots)\n",
    "train['street_cluster'] = kmeans.predict(train[['lat', 'lng']])\n",
    "test['street_cluster'] = kmeans.predict(test[['lat', 'lng']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Minute'] = train.Date_Time.dt.minute\n",
    "test['Minute'] = pd.to_datetime(test['Date_Time']).dt.minute\n",
    "train['Hour'] = train.Date_Time.dt.hour\n",
    "test['Hour'] = pd.to_datetime(test['Date_Time']).dt.hour\n",
    "train['Dow'] = train.Date_Time.dt.weekday\n",
    "test['Dow'] = pd.to_datetime(test['Date_Time']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Time'] = train[\"Hour\"]*100 + train['Minute']\n",
    "test['Time'] = test[\"Hour\"]*100 + test['Minute']\n",
    "train['isweekend'] = train['Dow'].apply(day_type)\n",
    "test['isweekend'] = test['Dow'].apply(day_type)\n",
    "train['From_To'] = train['From'] + '_' + train['To']\n",
    "test['From_To'] = test['From'] + '_' + test['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Dow','isweekend','From_To','Street','Hour', 'street_cluster' ]\n",
    "multi_reg_mean_encoding(train, cols, splits =5)\n",
    "multi_test_mean_encoding(test, train, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colpairs = [('street_cluster','Dow'),('Dow','Hour'), ('street_cluster','Hour'),\n",
    "            ('street_cluster','isweekend'),('From_To','Dow'),('From_To','Hour')]\n",
    "pairlist = []\n",
    "for pair in colpairs:\n",
    "    colname = pair[0] + '_' + pair[1]\n",
    "    pairlist.append(colname)\n",
    "    train[colname] = list(zip(train[pair[0]], train[pair[1]]))\n",
    "    test[colname] = list(zip(test[pair[0]], test[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_reg_mean_encoding(train, pairlist, splits =5)\n",
    "multi_test_mean_encoding(test, train, pairlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Date_Time','Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis =1)\n",
    "test = test.drop(['Date_Time', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Street'] = train.Street.str.lower()\n",
    "train['From'] = train.From.str.lower()\n",
    "train['To'] = train.To.str.lower()\n",
    "test['Street'] = test.Street.str.lower()\n",
    "test['From'] = test.From.str.lower()\n",
    "test['To'] = test.To.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "test = pd.merge(test,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "\n",
    "train = train.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)\n",
    "test = test.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catcols = ['Street','From','To', 'From_To']\n",
    "train,test = process_dfs(train.copy(),test.copy(),catcols)\n",
    "train,test = cat2code(train,test,catcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = split_response(train.copy(),'any_spot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop unimportant features\n",
    "X_train.drop(to_drop_dow, axis = 1, inplace=True)\n",
    "test.drop(to_drop_dow, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit rf\n",
    "np.random.seed(42)\n",
    "m_dow = RandomForestClassifier(n_estimators = 40, max_depth =5, max_features=0.4, class_weight={0:1,1:0.8}, min_samples_split = 2, n_jobs=-1)\n",
    "m_dow.fit(X_train,y_train)\n",
    "pred_dow = m_dow.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"id\": np.arange(1,len(test)+1),\"any_spot\":pred_dow})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result[['id','any_spot']].to_csv(\"../submissions/32_dow_test.csv\", index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By DOW: \n",
    "\n",
    "Result from leaderboard: 0.55749\n",
    "\n",
    "on validation set: 0.616883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
