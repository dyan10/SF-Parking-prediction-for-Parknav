{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train-parking.csv', parse_dates=[[3,4]], infer_datetime_format=True)\n",
    "test=pd.read_csv('../data/test-no-label-parking.csv', parse_dates=[[3,4]], infer_datetime_format=True)\n",
    "valid_dow = pd.read_csv('../data/valid_dow.csv', infer_datetime_format=True, index_col='index').set_index('index.1')\n",
    "valid_hg = pd.read_csv('../data/valid_hg.csv', infer_datetime_format=True, index_col='index').set_index('index.1')\n",
    "valid_swhg = pd.read_csv('../data/valid_swhg.csv', infer_datetime_format=True, index_col='index').set_index('index.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Street</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Real.Spots</th>\n",
       "      <th>Street.Length</th>\n",
       "      <th>any_spot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-07 16:19:00</td>\n",
       "      <td>Mission Street</td>\n",
       "      <td>25th Street</td>\n",
       "      <td>26th Street</td>\n",
       "      <td>4</td>\n",
       "      <td>179.132970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-18 20:42:00</td>\n",
       "      <td>Polk Street</td>\n",
       "      <td>Ellis Street</td>\n",
       "      <td>Olive Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.740210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-18 20:39:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Geary Boulevard</td>\n",
       "      <td>Myrtle Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.517840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-18 20:38:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Bush Street</td>\n",
       "      <td>Fern Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.405315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-18 20:38:00</td>\n",
       "      <td>Van Ness Avenue</td>\n",
       "      <td>Daniel Burnham Court</td>\n",
       "      <td>Post Street</td>\n",
       "      <td>0</td>\n",
       "      <td>52.191193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date_Time           Street                  From             To  \\\n",
       "0 2014-01-07 16:19:00   Mission Street           25th Street    26th Street   \n",
       "1 2014-01-18 20:42:00      Polk Street          Ellis Street   Olive Street   \n",
       "2 2014-01-18 20:39:00  Van Ness Avenue       Geary Boulevard  Myrtle Street   \n",
       "3 2014-01-18 20:38:00  Van Ness Avenue           Bush Street    Fern Street   \n",
       "4 2014-01-18 20:38:00  Van Ness Avenue  Daniel Burnham Court    Post Street   \n",
       "\n",
       "   Real.Spots  Street.Length  any_spot  \n",
       "0           4     179.132970         1  \n",
       "1           0      52.740210         0  \n",
       "2           0      52.517840         0  \n",
       "3           0      52.405315         0  \n",
       "4           0      52.191193         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the proper train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dow = train[~train.index.isin(valid_dow.index)]\n",
    "train_hg = train[~train.index.isin(valid_hg.index)]\n",
    "train_swhg = train[~train.index.isin(valid_swhg.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select validation set - round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get long and lat for train street\n",
    "st_latlng = pd.read_csv(\"../data/train_longlat.csv\", index_col = False,  dtype = {'lat':np.float64,'lng':np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_hg = pd.merge(train_hg,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "valid_hg= pd.merge(valid_hg,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sensor related data\n",
    "sensor = pd.read_csv('../data/aggregated_sensor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensor['TIME_OF_DAY'] = sensor['TIME_OF_DAY']/100\n",
    "sensor['TIME_OF_DAY'] = sensor['TIME_OF_DAY'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "spots = np.vstack(train_hg[['lat','lng']].values)\n",
    "kmeans = KMeans().fit(spots)\n",
    "train_hg['street_cluster'] = kmeans.predict(train_hg[['lat', 'lng']])\n",
    "valid_hg['street_cluster'] = kmeans.predict(valid_hg[['lat', 'lng']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Time features\n",
    "train_hg['Minute'] = train_hg.Date_Time.dt.minute\n",
    "valid_hg['Minute'] = pd.to_datetime(valid_hg['Date_Time']).dt.minute\n",
    "train_hg['Hour'] = train_hg.Date_Time.dt.hour\n",
    "valid_hg['Hour'] = pd.to_datetime(valid_hg['Date_Time']).dt.hour\n",
    "train_hg['Dow'] = train_hg.Date_Time.dt.weekday\n",
    "valid_hg['Dow'] = pd.to_datetime(valid_hg['Date_Time']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the time (Hour, Minute) to a numerical value XXXX\n",
    "train_hg['Time'] = train_hg[\"Hour\"]*100 + train_hg['Minute']\n",
    "valid_hg['Time'] = valid_hg[\"Hour\"]*100 + valid_hg['Minute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def day_type(x):\n",
    "    if x == 6 or x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "train_hg['isweekend'] = train_hg['Dow'].apply(day_type)\n",
    "valid_hg['isweekend'] = valid_hg['Dow'].apply(day_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Single mean encoding\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def multi_reg_mean_encoding(train, cols, splits =5):\n",
    "    kf = KFold(n_splits = splits)\n",
    "    global_mean = train.any_spot.mean()\n",
    "    \n",
    "    for col in cols:\n",
    "        means = train.groupby(col).any_spot.mean()\n",
    "        train[col+'_mean_enc'] = train[col].map(means)        \n",
    "        for tr_ind,val_ind in kf.split(train):\n",
    "            tr,val = train.iloc[tr_ind],train.iloc[val_ind]\n",
    "            foldmeans = tr.groupby(col).any_spot.mean()\n",
    "            train.loc[val_ind,col+\"_mean_enc\"] = train.loc[val_ind,col].map(foldmeans)    \n",
    "        train[col+\"_mean_enc\"].fillna(global_mean,inplace=True)   \n",
    "        \n",
    "#mean encoding for validation and test data\n",
    "def multi_test_mean_encoding(test, train, cols):\n",
    "    for col in cols:\n",
    "        global_mean = train.any_spot.mean()\n",
    "        means = train.groupby(col).any_spot.mean()\n",
    "        test[col+\"_mean_enc\"] = test[col].map(means)\n",
    "        test[col+\"_mean_enc\"].fillna(global_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a column for From_To pair\n",
    "train_hg['From_To'] = train_hg['From'] + '_' + train_hg['To']\n",
    "valid_hg['From_To'] = valid_hg['From'] + '_' + valid_hg['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Dow','isweekend','From_To','Street','Hour', 'street_cluster' ]\n",
    "multi_reg_mean_encoding(train_hg, cols, splits =5)\n",
    "multi_test_mean_encoding(valid_hg, train_hg, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Double variable mean encoding\n",
    "colpairs = [('street_cluster','Dow'),('Dow','Hour'), ('street_cluster','Hour'),\n",
    "            ('street_cluster','isweekend'),('From_To','Dow'),('From_To','Hour')]\n",
    "pairlist = []\n",
    "for pair in colpairs:\n",
    "    colname = pair[0] + '_' + pair[1]\n",
    "    pairlist.append(colname)\n",
    "    train_hg[colname] = list(zip(train_hg[pair[0]], train_hg[pair[1]]))\n",
    "    valid_hg[colname] = list(zip(valid_hg[pair[0]], valid_hg[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_reg_mean_encoding(train_hg, pairlist, splits =5)\n",
    "multi_test_mean_encoding(valid_hg, train_hg, pairlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop Data_Time, Real.Spots, street_cluster_Dow, Dow_Hour, street_cluster_Hour, street_cluster_isweekend, From_To_Dow, From_To_Hour\n",
    "train_hg = train_hg.drop(['Date_Time','Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis =1)\n",
    "valid_hg = valid_hg.drop(['Date_Time', 'Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_hg['Street'] = train_hg.Street.str.lower()\n",
    "train_hg['From'] = train_hg.From.str.lower()\n",
    "train_hg['To'] = train_hg.To.str.lower()\n",
    "valid_hg['Street'] = valid_hg.Street.str.lower()\n",
    "valid_hg['From'] = valid_hg.From.str.lower()\n",
    "valid_hg['To'] = valid_hg.To.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join sensor data:\n",
    "train_hg = pd.merge(train_hg,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "valid_hg = pd.merge(valid_hg,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "\n",
    "train_hg = train_hg.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)\n",
    "valid_hg = valid_hg.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert categorical variables to code\n",
    "def process_dfs(train_df, test_df, cols):\n",
    "    # transfer categorical \n",
    "    for name in cols:\n",
    "        train_df[name]=train_df[name].astype('category').cat.as_ordered()\n",
    "        test_df[name] = pd.Categorical(test_df[name], categories=train_df[name].cat.categories, ordered=True)\n",
    "    return train_df, test_df\n",
    "  \n",
    "def cat2code(train_df, test_df, cols):\n",
    "    # transfer categorical \n",
    "    for name in cols:\n",
    "        train_df[name]= train_df[name].cat.codes\n",
    "        test_df[name] = test_df[name].cat.codes\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catcols = ['Street','From','To', 'From_To']\n",
    "train_hg,valid_hg = process_dfs(train_hg.copy(),valid_hg.copy(),catcols)\n",
    "train_hg,valid_hg = cat2code(train_hg,valid_hg,catcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y\n",
    "def split_response(df, response):\n",
    "    y = df[response].values\n",
    "    df.drop([response],axis=1,inplace=True)\n",
    "    return df,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_hg,y_train_hg = split_response(train_hg.copy(),'any_spot')\n",
    "X_valid_hg,y_valid_hg = split_response(valid_hg.copy(),'any_spot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f05_score_soft(labels, preds):\n",
    "    tp = np.sum((labels==(preds>0.5)) & (labels==1))\n",
    "    tn = np.sum((labels==(preds<0.5)) & (labels==0))\n",
    "    fp = np.sum((preds>0.5))-tp\n",
    "    fn = np.sum(preds<0.5)-tn\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "    score = 1.25*p*r/(0.25*p+r)\n",
    "    return score\n",
    "\n",
    "def f05_score_hard(labels, preds):\n",
    "    tp = np.sum((labels==preds) & (labels==1))\n",
    "    tn = np.sum((labels==preds) & (labels==0))\n",
    "    fp = np.sum(preds==1)-tp\n",
    "    fn = np.sum(preds==0)-tn\n",
    "#    print(tp, tn, fp, fn)\n",
    "    p = tp*1.0/(tp+fp)\n",
    "    r = tp*1.0/(tp+fn)\n",
    "    score = 1.25*p*r/(0.25*p+r)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manual gridsearch using validation set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import itertools\n",
    "\n",
    "n_estimators = [20, 40, 60, 80]\n",
    "max_depth = [3,5,10,15,20,25,30]\n",
    "max_features = [0.2,0.4,0.5,0.6,0.8,0.9,1]\n",
    "weight = [0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "para_lists = [n_estimators, max_depth, max_features, weight]\n",
    "combo = list(itertools.product(*para_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = []\n",
    "f05 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for p in combo:\n",
    "    np.random.seed(42)\n",
    "    m = RandomForestClassifier(n_estimators = p[0], max_depth =p[1], max_features=p[2],class_weight={0:1,1:p[3]}, min_samples_split = 2, n_jobs=-1)\n",
    "    m.fit(X_train_hg,y_train_hg)\n",
    "    pred = m.predict(X_valid_hg)\n",
    "    prec = precision_score(y_valid_hg, pred)\n",
    "    rec = recall_score(y_valid_hg, pred)\n",
    "    f = f05_score_hard(y_valid_hg, pred)\n",
    "    parameters.append(p)\n",
    "    f05.append(f)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "\n",
    "table2 = pd.DataFrame({'Parameters': parameters, 'f0.5': f05, 'precision':precision, 'recall':recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table2.sort_values('f0.5', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>f0.5</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>(40, 25, 1, 1.5)</td>\n",
       "      <td>0.583039</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.417722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>(40, 30, 1, 1.5)</td>\n",
       "      <td>0.583039</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.417722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>(40, 5, 0.5, 0.7)</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.316456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>(40, 15, 1, 1.1)</td>\n",
       "      <td>0.573477</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.405063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>(20, 20, 0.4, 0.9)</td>\n",
       "      <td>0.572755</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.468354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Parameters      f0.5  precision    recall\n",
       "818    (40, 25, 1, 1.5)  0.583039   0.647059  0.417722\n",
       "881    (40, 30, 1, 1.5)  0.583039   0.647059  0.417722\n",
       "522   (40, 5, 0.5, 0.7)  0.581395   0.735294  0.316456\n",
       "688    (40, 15, 1, 1.1)  0.573477   0.640000  0.405063\n",
       "263  (20, 20, 0.4, 0.9)  0.572755   0.606557  0.468354"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the best hyperparameters (40, 25, 1, 1.5) to get feature importance:\n",
    "np.random.seed(42)\n",
    "m2 = RandomForestClassifier(n_estimators = 40, max_depth =25, max_features=1, class_weight={0:1,1:1.5}, min_samples_split = 2, n_jobs=-1)\n",
    "m2.fit(X_train_hg,y_train_hg)\n",
    "\n",
    "feat_imp_hg = pd.DataFrame({\n",
    "    'features': X_train_hg.columns,\n",
    "    'imp' :m2.feature_importances_\n",
    "})\n",
    "feat_imp_hg.sort_values(by='imp', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Street.Length</td>\n",
       "      <td>0.049633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.045867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Minute</td>\n",
       "      <td>0.044440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From_To_mean_enc</td>\n",
       "      <td>0.041422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From_To</td>\n",
       "      <td>0.038419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lat</td>\n",
       "      <td>0.034857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lng</td>\n",
       "      <td>0.034227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From</td>\n",
       "      <td>0.031935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To</td>\n",
       "      <td>0.030489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TOTAL_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.025186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Street_mean_enc</td>\n",
       "      <td>0.025136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dow_Hour_mean_enc</td>\n",
       "      <td>0.025048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>From_To_Dow_mean_enc</td>\n",
       "      <td>0.024776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TOTAL_VACANT_TIME_pct</td>\n",
       "      <td>0.024359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>street_cluster_Hour_mean_enc</td>\n",
       "      <td>0.024331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NONOP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.023317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>street_cluster_Dow_mean_enc</td>\n",
       "      <td>0.021856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TOTAL_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.021167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>street_cluster</td>\n",
       "      <td>0.021158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>street_cluster_isweekend_mean_enc</td>\n",
       "      <td>0.020796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hour</td>\n",
       "      <td>0.020535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From_To_Hour_mean_enc</td>\n",
       "      <td>0.020423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NONOP_VACANT_TIME_pct</td>\n",
       "      <td>0.019674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>street_cluster_mean_enc</td>\n",
       "      <td>0.019516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GMP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.019502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NONOP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.019206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hour_mean_enc</td>\n",
       "      <td>0.018795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GMP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.018751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dow_mean_enc</td>\n",
       "      <td>0.017981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TOTAL_TIME_spots</td>\n",
       "      <td>0.017878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>OP_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.017028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NONOP_TIME_spots</td>\n",
       "      <td>0.015828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>OP_VACANT_TIME_pct</td>\n",
       "      <td>0.015415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GMP_VACANT_TIME_pct</td>\n",
       "      <td>0.015341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>OP_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.015326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GMP_TIME_spots</td>\n",
       "      <td>0.014622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>OP_TIME_spots</td>\n",
       "      <td>0.014058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>isweekend_mean_enc</td>\n",
       "      <td>0.013934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>COMM_VACANT_TIME_pct</td>\n",
       "      <td>0.013521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dow</td>\n",
       "      <td>0.013521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Street</td>\n",
       "      <td>0.013519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>COMM_OCCUPIED_TIME_pct</td>\n",
       "      <td>0.013038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>COMM_UNKNOWN_TIME_pct</td>\n",
       "      <td>0.012272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>COMM_TIME_spots</td>\n",
       "      <td>0.006272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>isweekend</td>\n",
       "      <td>0.005624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             features       imp\n",
       "3                       Street.Length  0.049633\n",
       "10                               Time  0.045867\n",
       "7                              Minute  0.044440\n",
       "15                   From_To_mean_enc  0.041422\n",
       "12                            From_To  0.038419\n",
       "4                                 lat  0.034857\n",
       "5                                 lng  0.034227\n",
       "1                                From  0.031935\n",
       "2                                  To  0.030489\n",
       "25            TOTAL_OCCUPIED_TIME_pct  0.025186\n",
       "16                    Street_mean_enc  0.025136\n",
       "20                  Dow_Hour_mean_enc  0.025048\n",
       "23               From_To_Dow_mean_enc  0.024776\n",
       "26              TOTAL_VACANT_TIME_pct  0.024359\n",
       "21       street_cluster_Hour_mean_enc  0.024331\n",
       "31            NONOP_OCCUPIED_TIME_pct  0.023317\n",
       "19        street_cluster_Dow_mean_enc  0.021856\n",
       "27             TOTAL_UNKNOWN_TIME_pct  0.021167\n",
       "6                      street_cluster  0.021158\n",
       "22  street_cluster_isweekend_mean_enc  0.020796\n",
       "8                                Hour  0.020535\n",
       "24              From_To_Hour_mean_enc  0.020423\n",
       "32              NONOP_VACANT_TIME_pct  0.019674\n",
       "18            street_cluster_mean_enc  0.019516\n",
       "34              GMP_OCCUPIED_TIME_pct  0.019502\n",
       "33             NONOP_UNKNOWN_TIME_pct  0.019206\n",
       "17                      Hour_mean_enc  0.018795\n",
       "36               GMP_UNKNOWN_TIME_pct  0.018751\n",
       "13                       Dow_mean_enc  0.017981\n",
       "40                   TOTAL_TIME_spots  0.017878\n",
       "28               OP_OCCUPIED_TIME_pct  0.017028\n",
       "42                   NONOP_TIME_spots  0.015828\n",
       "29                 OP_VACANT_TIME_pct  0.015415\n",
       "35                GMP_VACANT_TIME_pct  0.015341\n",
       "30                OP_UNKNOWN_TIME_pct  0.015326\n",
       "43                     GMP_TIME_spots  0.014622\n",
       "41                      OP_TIME_spots  0.014058\n",
       "14                 isweekend_mean_enc  0.013934\n",
       "38               COMM_VACANT_TIME_pct  0.013521\n",
       "9                                 Dow  0.013521\n",
       "0                              Street  0.013519\n",
       "37             COMM_OCCUPIED_TIME_pct  0.013038\n",
       "39              COMM_UNKNOWN_TIME_pct  0.012272\n",
       "44                    COMM_TIME_spots  0.006272\n",
       "11                          isweekend  0.005624"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop feature if FI<0.015\n",
    "to_drop_hg = feat_imp_hg[feat_imp_hg['imp'] <= 0.015].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOW-retrain entire model - remember to drop insignificant columns in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "test= pd.merge(test,st_latlng,how ='left',left_on=[\"Street\",\"From\",\"To\"], right_on=[\"Street\",\"From\",\"To\"])\n",
    "\n",
    "spots = np.vstack(train[['lat','lng']].values)\n",
    "kmeans = KMeans().fit(spots)\n",
    "train['street_cluster'] = kmeans.predict(train[['lat', 'lng']])\n",
    "test['street_cluster'] = kmeans.predict(test[['lat', 'lng']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Minute'] = train.Date_Time.dt.minute\n",
    "test['Minute'] = pd.to_datetime(test['Date_Time']).dt.minute\n",
    "train['Hour'] = train.Date_Time.dt.hour\n",
    "test['Hour'] = pd.to_datetime(test['Date_Time']).dt.hour\n",
    "train['Dow'] = train.Date_Time.dt.weekday\n",
    "test['Dow'] = pd.to_datetime(test['Date_Time']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Time'] = train[\"Hour\"]*100 + train['Minute']\n",
    "test['Time'] = test[\"Hour\"]*100 + test['Minute']\n",
    "train['isweekend'] = train['Dow'].apply(day_type)\n",
    "test['isweekend'] = test['Dow'].apply(day_type)\n",
    "train['From_To'] = train['From'] + '_' + train['To']\n",
    "test['From_To'] = test['From'] + '_' + test['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Dow','isweekend','From_To','Street','Hour', 'street_cluster' ]\n",
    "multi_reg_mean_encoding(train, cols, splits =5)\n",
    "multi_test_mean_encoding(test, train, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colpairs = [('street_cluster','Dow'),('Dow','Hour'), ('street_cluster','Hour'),\n",
    "            ('street_cluster','isweekend'),('From_To','Dow'),('From_To','Hour')]\n",
    "pairlist = []\n",
    "for pair in colpairs:\n",
    "    colname = pair[0] + '_' + pair[1]\n",
    "    pairlist.append(colname)\n",
    "    train[colname] = list(zip(train[pair[0]], train[pair[1]]))\n",
    "    test[colname] = list(zip(test[pair[0]], test[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_reg_mean_encoding(train, pairlist, splits =5)\n",
    "multi_test_mean_encoding(test, train, pairlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Date_Time','Real.Spots', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis =1)\n",
    "test = test.drop(['Date_Time', 'street_cluster_Dow', 'Dow_Hour', 'street_cluster_Hour', 'street_cluster_isweekend', 'From_To_Dow', 'From_To_Hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Street'] = train.Street.str.lower()\n",
    "train['From'] = train.From.str.lower()\n",
    "train['To'] = train.To.str.lower()\n",
    "test['Street'] = test.Street.str.lower()\n",
    "test['From'] = test.From.str.lower()\n",
    "test['To'] = test.To.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "test = pd.merge(test,sensor, how='left',left_on=['Street','Dow','Hour'], right_on=['STREET_NAME','DOW','TIME_OF_DAY'])\n",
    "\n",
    "train = train.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)\n",
    "test = test.drop(['STREET_NAME','DOW','TIME_OF_DAY'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catcols = ['Street','From','To', 'From_To']\n",
    "train,test = process_dfs(train.copy(),test.copy(),catcols)\n",
    "train,test = cat2code(train,test,catcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train = split_response(train.copy(),'any_spot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop unimportant features\n",
    "X_train.drop(to_drop_hg, axis = 1, inplace=True)\n",
    "test.drop(to_drop_hg, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit rf\n",
    "np.random.seed(42)\n",
    "m_hg = RandomForestClassifier(n_estimators = 40, max_depth =25, max_features=1, class_weight={0:1,1:1.5}, min_samples_split = 2, n_jobs=-1)\n",
    "m_hg.fit(X_train,y_train)\n",
    "pred_hg = m_hg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"id\": np.arange(1,len(test)+1),\"any_spot\":pred_hg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result[['id','any_spot']].to_csv(\"../submissions/32_hg_test.csv\", index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Hour Group: \n",
    "\n",
    "Result from leaderboard: 0.51987\n",
    "\n",
    "on validation set: 0.583039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
